---
output: github_document
---

# contentAnalysis

<!-- badges: start -->
<!-- badges: end -->

`contentAnalysis` provides comprehensive tools for extracting and analyzing scientific content from PDF documents, including citation extraction, reference matching, text analysis, and bibliometric indicators.

## Features

- **PDF Import**: Multi-column layout support with structure preservation
- **Citation Extraction**: Comprehensive detection of citation formats (numbered, author-year, narrative, parenthetical)
- **Reference Parsing**: Extract references from text or CrossRef API
- **Citation-Reference Matching**: Automatic matching with multiple disambiguation strategies
- **Text Analysis**: Word frequencies, n-grams, lexical diversity
- **Citation Context**: Extract surrounding text for each citation
- **Bibliometric Indicators**: Citation density, distribution by section, co-occurrence networks
- **Word Distribution**: Track word frequencies across document sections

## Installation

You can install the development version from GitHub:
```r
# install.packages("devtools")
devtools::install_github("yourusername/contentAnalysis")
```

## Example

Complete workflow analyzing a real scientific paper:
```r
library(contentAnalysis)

# Download example paper (open access)
paper_url <- "https://raw.githubusercontent.com/massimoaria/contentAnalysis/master/inst/examples/example_paper.pdf"
download.file(paper_url, destfile = "example_paper.pdf", mode = "wb")

# Import PDF with automatic section detection
doc <- pdf2txt_auto("example_paper.pdf", n_columns = 2)

# Check detected sections
names(doc)
#> [1] "Full_text"    "Abstract"     "Introduction" "Methods"      
#> [5] "Results"      "Discussion"   "Conclusion"   "References"

# Perform comprehensive content analysis with CrossRef
analysis <- analyze_scientific_content_enhanced(
  text = doc,
  doi = "10.1016/j.mlwa.2021.100094",
  mailto = "your@email.com"
)

# View summary statistics
analysis$summary
#> $total_words_analyzed
#> [1] 4523
#> 
#> $citations_extracted
#> [1] 45
#> 
#> $references_parsed
#> [1] 42

# Examine citations by type
analysis$citation_metrics$type_distribution
#>                citation_type  n percentage
#> 1        author_year_basic   28      62.2
#> 2        narrative_single   12      26.7
#> 3   multiple_citations_semicolon    5      11.1

# Check matching quality
print_matching_diagnostics(analysis)
#> Total citations: 45 
#> Total references parsed: 42 
#> Match rate: 93.3 %
#> High confidence matches: 40

# Analyze citation contexts
head(analysis$citation_contexts[, c("citation_text_clean", "section", "full_context")])

# Track methodological terms across sections
method_terms <- c("machine learning", "regression", "validation", "dataset")
word_dist <- calculate_word_distribution(doc, method_terms)

# Create interactive visualization
plot_word_distribution(word_dist, plot_type = "line", show_points = TRUE)

# Examine most frequent words
head(analysis$word_frequencies, 10)

# Citation co-occurrence network
head(analysis$network_data)
```

### Working with references
```r
# View parsed references
head(analysis$parsed_references[, c("ref_first_author", "ref_year", "ref_full_text")])

# Find citations to specific author
library(dplyr)
analysis$citation_references_mapping %>%
  filter(grepl("Smith", ref_authors, ignore.case = TRUE))

# Citations by section
analysis$citation_metrics$section_distribution
#>       section  n percentage
#> 1 Introduction 15      33.3
#> 2     Methods  8      17.8
#> 3     Results 12      26.7
#> 4  Discussion 10      22.2
```

### Advanced: Word distribution analysis
```r
# Track disease-related terms
disease_terms <- c("covid", "pandemic", "health", "policy", "vaccination")
dist <- calculate_word_distribution(doc, disease_terms, use_sections = TRUE)

# View frequencies by section
dist %>%
  select(segment_name, word, count, percentage) %>%
  arrange(segment_name, desc(percentage))

# Visualize trends
plot_word_distribution(dist, plot_type = "area", smooth = FALSE)
```

## Main Functions

- `pdf2txt_auto()`: Import PDF with automatic section detection
- `analyze_scientific_content_enhanced()`: Comprehensive content and citation analysis
- `parse_references_section()`: Parse reference list
- `match_citations_to_references()`: Match citations to references
- `calculate_word_distribution()`: Track word frequencies across sections
- `plot_word_distribution()`: Interactive visualization of word distribution

## Dependencies

Core: pdftools, dplyr, tidyr, stringr, tidytext, tibble, httr2

Suggested: plotly, RColorBrewer, scales (for visualization)

## Citation

If you use this package in your research, please cite:
```
Your Name (2025). contentAnalysis: Scientific Content and Citation Analysis from PDF Documents.
R package version 0.1.0.
```
